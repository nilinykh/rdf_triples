{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/xilini/webnlg/submissions2020/corpus-reader-master/')\n",
    "\n",
    "from benchmark_reader import Benchmark\n",
    "from benchmark_reader import select_files\n",
    "import json\n",
    "\n",
    "# extract reference texts\n",
    "b = Benchmark()\n",
    "b.fill_benchmark([('/home/xilini/webnlg/submissions2020/testdata/rdf2text/en/',\n",
    "                   'rdf-to-text-generation-test-data-with-refs-en.xml')])\n",
    "b.b2json('./', 'data_REF.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../inputs/sampled_ids.txt', 'r') as f2:\n",
    "    sampled_ids = f2.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data_REF.json', 'r') as f1:\n",
    "    data_REF = json.load(f1)['entries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data_REF = []\n",
    "cats = {}\n",
    "for item in data_REF:\n",
    "    for key, value in item.items():\n",
    "        if key in sampled_ids:\n",
    "            sampled_data_REF.append(item)\n",
    "            cats[key] = value['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'3': 'Airport',\n",
       " '29': 'Politician',\n",
       " '34': 'Artist',\n",
       " '68': 'MusicalWork',\n",
       " '80': 'Film',\n",
       " '83': 'MusicalWork',\n",
       " '128': 'WrittenWork',\n",
       " '129': 'Politician',\n",
       " '142': 'University',\n",
       " '152': 'MusicalWork',\n",
       " '165': 'Athlete',\n",
       " '169': 'Building',\n",
       " '184': 'Film',\n",
       " '187': 'MusicalWork',\n",
       " '188': 'MeanOfTransportation',\n",
       " '192': 'Film',\n",
       " '195': 'Building',\n",
       " '203': 'Artist',\n",
       " '207': 'Scientist',\n",
       " '224': 'Artist',\n",
       " '237': 'SportsTeam',\n",
       " '240': 'MusicalWork',\n",
       " '256': 'MusicalWork',\n",
       " '267': 'Company',\n",
       " '286': 'Film',\n",
       " '287': 'Film',\n",
       " '292': 'Artist',\n",
       " '300': 'University',\n",
       " '301': 'SportsTeam',\n",
       " '307': 'Film',\n",
       " '350': 'City',\n",
       " '377': 'Scientist',\n",
       " '383': 'MusicalWork',\n",
       " '388': 'Scientist',\n",
       " '390': 'Astronaut',\n",
       " '392': 'Monument',\n",
       " '417': 'MusicalWork',\n",
       " '419': 'Scientist',\n",
       " '441': 'MusicalWork',\n",
       " '448': 'MusicalWork',\n",
       " '452': 'MusicalWork',\n",
       " '455': 'Food',\n",
       " '483': 'Film',\n",
       " '489': 'Scientist',\n",
       " '496': 'Astronaut',\n",
       " '498': 'Athlete',\n",
       " '500': 'Company',\n",
       " '514': 'MusicalWork',\n",
       " '531': 'Artist',\n",
       " '533': 'Athlete',\n",
       " '534': 'MeanOfTransportation',\n",
       " '556': 'Politician',\n",
       " '564': 'MusicalWork',\n",
       " '565': 'MusicalWork',\n",
       " '578': 'Artist',\n",
       " '590': 'Scientist',\n",
       " '595': 'Scientist',\n",
       " '597': 'MusicalWork',\n",
       " '618': 'Athlete',\n",
       " '622': 'City',\n",
       " '636': 'MusicalWork',\n",
       " '648': 'WrittenWork',\n",
       " '650': 'Monument',\n",
       " '656': 'MusicalWork',\n",
       " '665': 'MusicalWork',\n",
       " '667': 'Monument',\n",
       " '677': 'MusicalWork',\n",
       " '682': 'University',\n",
       " '683': 'Food',\n",
       " '687': 'ComicsCharacter',\n",
       " '725': 'MusicalWork',\n",
       " '732': 'Scientist',\n",
       " '734': 'MeanOfTransportation',\n",
       " '762': 'MusicalWork',\n",
       " '789': 'Food',\n",
       " '802': 'MusicalWork',\n",
       " '817': 'Athlete',\n",
       " '830': 'Artist',\n",
       " '859': 'MeanOfTransportation',\n",
       " '862': 'Film',\n",
       " '873': 'Scientist',\n",
       " '890': 'Building',\n",
       " '907': 'MusicalWork',\n",
       " '912': 'WrittenWork',\n",
       " '918': 'Company',\n",
       " '923': 'City',\n",
       " '967': 'MusicalWork',\n",
       " '976': 'Company',\n",
       " '977': 'Scientist',\n",
       " '996': 'MusicalWork',\n",
       " '997': 'Airport',\n",
       " '1003': 'Company',\n",
       " '1009': 'Film',\n",
       " '1011': 'Scientist',\n",
       " '1034': 'MusicalWork',\n",
       " '1041': 'Airport',\n",
       " '1048': 'SportsTeam',\n",
       " '1068': 'Film',\n",
       " '1069': 'Scientist',\n",
       " '1075': 'MusicalWork',\n",
       " '1091': 'MusicalWork',\n",
       " '1107': 'Scientist',\n",
       " '1108': 'Athlete',\n",
       " '1113': 'Scientist',\n",
       " '1121': 'Scientist',\n",
       " '1122': 'Airport',\n",
       " '1124': 'MusicalWork',\n",
       " '1129': 'CelestialBody',\n",
       " '1132': 'Film',\n",
       " '1147': 'University',\n",
       " '1163': 'Building',\n",
       " '1179': 'WrittenWork',\n",
       " '1188': 'University',\n",
       " '1195': 'Film',\n",
       " '1203': 'Film',\n",
       " '1204': 'Building',\n",
       " '1208': 'Scientist',\n",
       " '1222': 'MusicalWork',\n",
       " '1233': 'Film',\n",
       " '1236': 'Film',\n",
       " '1252': 'Politician',\n",
       " '1254': 'SportsTeam',\n",
       " '1255': 'Company',\n",
       " '1267': 'ComicsCharacter',\n",
       " '1281': 'University',\n",
       " '1291': 'CelestialBody',\n",
       " '1312': 'MusicalWork',\n",
       " '1314': 'University',\n",
       " '1345': 'University',\n",
       " '1353': 'Scientist',\n",
       " '1369': 'Airport',\n",
       " '1391': 'Monument',\n",
       " '1392': 'University',\n",
       " '1400': 'University',\n",
       " '1401': 'Astronaut',\n",
       " '1433': 'MusicalWork',\n",
       " '1435': 'Scientist',\n",
       " '1442': 'MusicalWork',\n",
       " '1445': 'MeanOfTransportation',\n",
       " '1448': 'Film',\n",
       " '1455': 'WrittenWork',\n",
       " '1474': 'Airport',\n",
       " '1495': 'Food',\n",
       " '1496': 'Food',\n",
       " '1499': 'University',\n",
       " '1548': 'Artist',\n",
       " '1552': 'Company',\n",
       " '1553': 'CelestialBody',\n",
       " '1604': 'City',\n",
       " '1606': 'University',\n",
       " '1608': 'Athlete',\n",
       " '1625': 'Scientist',\n",
       " '1628': 'SportsTeam',\n",
       " '1635': 'SportsTeam',\n",
       " '1638': 'Scientist',\n",
       " '1645': 'MusicalWork',\n",
       " '1646': 'MusicalWork',\n",
       " '1649': 'University',\n",
       " '1660': 'University',\n",
       " '1663': 'City',\n",
       " '1669': 'MeanOfTransportation',\n",
       " '1671': 'Scientist',\n",
       " '1683': 'City',\n",
       " '1690': 'Film',\n",
       " '1691': 'MusicalWork',\n",
       " '1696': 'Film',\n",
       " '1699': 'Company',\n",
       " '1700': 'Monument',\n",
       " '1716': 'Scientist',\n",
       " '1721': 'SportsTeam',\n",
       " '1726': 'MusicalWork',\n",
       " '1730': 'MusicalWork',\n",
       " '1731': 'SportsTeam',\n",
       " '1740': 'Artist',\n",
       " '1742': 'WrittenWork',\n",
       " '1752': 'City',\n",
       " '1773': 'Scientist',\n",
       " '1777': 'Company'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicalisations = {}\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "for entry in sampled_data_REF:\n",
    "    lexs = []\n",
    "    for k, v in entry.items():\n",
    "        lex = v['lexicalisations']\n",
    "        for i in lex:\n",
    "            lexs.append(i['lex'])\n",
    "    this_lex = random.sample(lexs, 1)\n",
    "    lexicalisations[k] = this_lex[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../inputs/texts_REF.json', 'w') as f3:\n",
    "    json.dump(lexicalisations, f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare triples\n",
    "triplet_data = {}\n",
    "\n",
    "# save info about triple size\n",
    "triple_size = {}\n",
    "\n",
    "for entry in sampled_data_REF:\n",
    "    lexs = []\n",
    "    rows = []\n",
    "    for k, v in entry.items():\n",
    "        n = 0\n",
    "        triples = v['modifiedtripleset']       \n",
    "        for t in triples:\n",
    "            subj = t['subject'].replace('_', ' ')\n",
    "            pred = t['property'].replace('_', ' ')\n",
    "            obj = t['object'].replace('_', ' ')\n",
    "            this_t = [subj, pred, obj]\n",
    "            rows.append(this_t)\n",
    "            n += 1\n",
    "        triple_size[k] = n\n",
    "                \n",
    "    triplet_data[k] = []\n",
    "    triplet_data[k].append(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./triple_size.json', 'w') as f3:\n",
    "    json.dump(triple_size, f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_triplet = '''\n",
    "\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\">SUBJ</td>\n",
    "    <td class=\"tg-0lax\">PRED</td>\n",
    "    <td class=\"tg-0lax\">OBJ</td>\n",
    "  </tr>\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_head = '''\n",
    "\n",
    "<div class=\"center\">\n",
    "<table class=\"tg\">\n",
    "\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-0pky\"><b>Subject</b></th>\n",
    "    <th class=\"tg-0pky\"><b>Predicate</b></th>\n",
    "    <th class=\"tg-0pky\"><b>Object</b></th>\n",
    "  </tr>\n",
    "</thead>\n",
    "\n",
    "<tbody>\n",
    "REPLACE_DATA\n",
    "</tbody>\n",
    "\n",
    "</table>\n",
    "</div>\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "qual_triplets_vis = {}\n",
    "for sample_id, triplet_set in triplet_data.items():\n",
    "    xml_set = ''\n",
    "    for this_set in triplet_set:\n",
    "        for item in this_set:\n",
    "            subj, pred, obj = item\n",
    "            this_xml_triplet = html_triplet.replace('SUBJ', subj).replace('PRED', pred).replace('OBJ', obj)\n",
    "            xml_set += this_xml_triplet\n",
    "    full_xml_table = html_head.replace('REPLACE_DATA', xml_set)\n",
    "    qual_triplets_vis[sample_id] = full_xml_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qual_triplets_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../inputs/triples_REF.json', 'w') as f0:\n",
    "    json.dump(qual_triplets_vis, f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare texts from the baseline and submissions\n",
    "\n",
    "submission_path = '../../../submissions2020/RDF-to-Text(English)/sub/'\n",
    "\n",
    "with open(submission_path + 'baseline_WebNLG-2020-FORGe2020-12-2_submission.en', 'r') as f1:\n",
    "    texts_BASELINE = f1.read().splitlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = {}\n",
    "for num, text in enumerate(texts_BASELINE, 1):\n",
    "    if str(num) in sampled_ids:\n",
    "        texts[num] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./texts_BASELINE.json', 'w') as f4:\n",
    "    json.dump(texts, f4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./subm_paths.json', 'r') as f6:\n",
    "    subm_dict = json.load(f6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in subm_dict.items():\n",
    "    \n",
    "    with open(submission_path + v, 'r') as f:\n",
    "        texts = f.read().splitlines()\n",
    "    sampled_texts = {}\n",
    "    \n",
    "    for num, text in enumerate(texts, 1):\n",
    "        if str(num) in sampled_ids:\n",
    "            sampled_texts[num] = text\n",
    "            \n",
    "    with open(f'./texts_{k}.json', 'w') as f4:\n",
    "        json.dump(sampled_texts, f4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
